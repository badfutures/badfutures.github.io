---
layout: post
title:  "1. Not believing one's eyes"
date:   2019-08-10 13:38 +1000
---

Very recently I listened two world class pundits briefly discussing[^podcast] deepfakes and I was really surprised by their optimism about their impact and by their hope for a techincal solution. While both gentlemen expressed concern[^concern], one of the pundits - whom I admire a great deal - goes as far as to suggest that there even may be a positive aspect to the issue. 

My view is that proliferation of deepfakes changes everything and it is an existentional threat to humanity. 

[^podcast]:  [Kevin Scott: Microsoft CTO \| Artificial Intelligence (AI) Podcast](https://lexfridman.com/kevin-scott/), published 2019 Aug 02

[^concern]: Kevin Scott says that he finds deepfakes worrisome (36:30) and says "we're not ready for this". 

As of August 2019 Wikipedia uses the following definition: "Deepfake (a portmanteau of "deep learning" and "fake") is a technique for human image synthesis based on artificial intelligencei. It is used to combine and superimpose existing images and videos onto source images or videos using a machine learning technique known as generative adversarial network."[^deepfake_wiki] As of 2019 GANs (Generative Adversarial Networks), which are machine learning systems that use deep neural networks, are the cutting edge technology for creating deepfakes.

[^deepfake_wiki]: [Deepfake](https://en.wikipedia.org/wiki/Deepfake) by Wikipedia, retrieved 2019-08-11

It actually is not important if the fake clip is made using a deep neural network. The important issue is the apperance of an being an unaltered representation of reality and for this post I will use the following definition:

> Deepfake is an image, video, audioclip, or other content that does not present real events but is distributed as if it was, and which to a human does not appear to be articially generated or altered.

There were four theses postulated in the few minutes of the interview that was dedicated to deepfakes. I believe that all 4 were wrong.

**Fallacy 1. Broken trust = resilient individuals.** The claim here is that societies with no trust, with everpresent propaganda, with an untrustworty public discourse, were, in some sense, good. This is because this (un?)reality develops a kind of intellectual resiliency and encourages research. 

I challange this view on multiple levels:
1. Numbers: Skepticsm to good propaganda is present in only a fraction of the society. The majority just believes. For a non political example see think of advertising.
1. Causation: It is not clear at all that the desire to question news is unleashed by living in a Soviet Union style reality. Generally, (un)inquisitve minds will be (un)inquisitive in all systems. 
1. Resiliency: One cannot avoid being fooled all the time. Each one of us believes in something that isn't true because we saw, heard, or read some meterial that wasn't true. 
1. Need: While skepticism can be seen as a trait worth having, it's a reaction to bad circumstances. The level of skepticism is correlated with how untrustworthy the society is - skepticism is an antibody for the cancer of broken trust. On a coneptual level there is no need for sketpicsm. In my family I want trust, not skepticism. I want my children to trust me, not to expect lies. Home should feel safe and we should not see dangers hiding in corners. 
1. Consequences: What doesn't kill you makes you stronger mantra doesn't generally make sense, including the specific case of common distrust. How often do you wish that you cannot trust your friends and family and that from time to time to build up your skepticism they break your trust? How often do you hear advice to lie to make someone resilient and to encourage research?
   Let's consider these exapmles of consequences of broken trust:
     1. A conspiracy theorist: I don't think a person who doesn't trust a whole branch of reality is a great role model.
     1. A victim of deception: A person who was a subject of deception can be affected for a long time, and prolonged deception can cause serious mental issues. Deception it's doesn't build, it destroys. 
         
**Fallacy 2. Siver lining.** The claim here is that "Deepfakes (...) are creating global skepticism; (...) it encourages further research"[^lf-its-a-good-thing]

[^lf-its-a-good-thing]: Interview 40:45

This resoning is similar the first fallacy, but applied to the future. Silver lining thinking has been used to discuss the political shifts of the recent years but there is plenty of historical evidence that things need to turn really bad before societies start improving and that's only if they actually can start moving into the right direction without external forces. The most obvious example for my generation is [WWII](https://en.wikipedia.org/wiki/World_War_II)). None of the stages of the deterioration of democracy has shaken the world into action before it was too late. I believe that with deepfakes the damage will be too deep for the global society to repair itself and that there will be no external force to fix it. 

The unfouned hopefuless of both pundits is most comical when it's expressed in the same breath with the need for skepticism. 

[//]: #This hopefulness by Lex, who is Jewish is really surprising. Remember Protocols of Zion or the posters of greedy Jews?

**Fallacy 3. Skepticism will save us.** The claim here is that sketpicism is enough to deal with this. 

Firstly, I don't believe that there is that skepticsm will appear. Why would it? We needed more skepticism for claims that vaccines don't cause autism, or that there are no Elders of Zion, but for many it never arrived.

Secondly, again, it's not possible to be skeptical all the time about everything. How can one live, when nothing can be assumed real?

**Fallacy 4. A technology will fix it** This claim here is that a technology will emerge that will address the problem. One example is signing the videos which will allow verification.

The signing idea immediately raises many questions. For example, how would this signing work when news is presented? We often consume clips embedded in other clips. I cannot see how signing could work for verification if an embedded clip in a cornder of another clip is authentic. 

Even if we only interact with full signed clips, or the way we interact with clips changes, it's impractical to certify everthing. We don't sign our emails and we don't confirm if the downloaded software wasn't tempered with. 

The main counterargument is, however, that it doesn't matter if we can technically verify if something is real. We just won't do it, even if it's easy. There is a lot of information out there that can be easily proved untrue, but some of these lies are widely believed. As Joscha Bach eloquently points out[^Joscha], we seek data to confirm our views rather than adjust our views to fit with the facts. 

[^Joscha]: Singularity FM, (Joscha Bach: We need to understand the nature of AI to understand who we are)[https://www.singularityweblog.com/joscha-bach/], ~33:00 - 35:00, November 14, 2018	

It's important to point out that living in a society with broken trust is not the same as exposure to bad ideas. Iâ€™d argue that exposure is necessary for developing critical thinking and that we should not be using filtering to reduce it (filtering as in internet filter bubbles, sheltering children, or even removing bias from machine learning training data). I agree completely with Roman Yampolskiy when he says that we should teach bad ideas to students[^yampolskiy18]. 

[^yampolskiy18]: Singularity FM, [Roman Yampolskiy on Artificial Intelligence Safety and Security](https://www.singularityweblog.com/tag/roman-yampolskiy/), ~1:08, August 31, 2018 

Deefakes are exponential tools for propaganda and the arrival of deepfakes is the match that will ignite gaslighing on global scale. "Gaslighting is a form of psychological manipulation in which a person seeks to sow seeds of doubt in a targeted individual or in members of a targeted group, making them question their own memory, perception, and sanity. Using persistent denial, misdirection, contradiction, and lying, gaslighting involves attempts to destabilize the victim and delegitimize the victim's belief.[^gaslighting]"

[^gaslighting]: [wikipedia](https://en.wikipedia.org/wiki/Gaslighting)

The most obviously dangerous deepfakes are the ones distributed for the purpose of gaslighting, but I believe that all deepfakes are extremely dangerous, even the ones simingly beneficial (example from the interview: Microsoft uses deepfakes as input data for neural nets to avoid bias). This is because no matter what a deepfake is used for it breaks the chain of trust. It creates a new history of the universe (it's like multiple universes theory but in opposite direction to the arrow of time). These differnt histories cannot be shared between individuals. 

Let's consider this mental experiment. Imagine that you agree with your friends and people to send one another deepfakes from time to time. You getting deepfakes about the weather for the weekend, the time and place Friday gathering is at, if the book is worth reading. How much of faking is needed before you stop trusting anything? How long would it take before you literally go crazy? 

I believe deepfakes will rip the fabric of society. I know that many things were described as dangerous to this ephemeral concept, but society *IS* interactions between people and if its members cannot trust any communication the outlook doesn't look good.

